{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9748dec7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, Flatten\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import ConvLSTM2D\n",
    "\n",
    "adm_name = gpd.read_file('data/TSDM/Mandal_Boundary.shp')\n",
    "df = pd.read_csv('data/cropfire_taluk.csv', index_col=False)\n",
    "\n",
    "\n",
    "import time                                      #to calculate time taken to run the model\n",
    "start_time = time.time()                         #start time of the program\n",
    "\n",
    "place = []\n",
    "deviance = []\n",
    "\n",
    "for i in df.place.unique():\n",
    "  dataframe = pd.DataFrame()\n",
    "  dataframe = df.loc[df['place'] == i]\n",
    "  del dataframe['place']\n",
    "  dataframe = dataframe.reset_index()\n",
    "  del dataframe['index']\n",
    "\n",
    "  #Convert pandas dataframe to numpy array\n",
    "  dataset = dataframe.fireCount\n",
    "  dataset = dataset.astype('float32') #COnvert values to float\n",
    "  #LSTM uses sigmoid and tanh that are sensitive to magnitude so values need to be normalized\n",
    "  # normalize the dataset\n",
    "  scaler = MinMaxScaler(feature_range=(0, 1)) #Also try QuantileTransformer\n",
    "  dataset = np.array(dataset).reshape(-1,1)\n",
    "  dataset = scaler.fit_transform(dataset)\n",
    "  train_size = int(len(dataset)-365)\n",
    "  test_size = len(dataset) - train_size\n",
    "  train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "  print(test_size)\n",
    "\n",
    "\n",
    "  def to_sequences(dataset, seq_size=1):\n",
    "      x = []\n",
    "      y = []\n",
    "\n",
    "      for i in range(len(dataset)-seq_size-1):\n",
    "          #print(i)\n",
    "          window = dataset[i:(i+seq_size), 0]\n",
    "          x.append(window)\n",
    "          y.append(dataset[i+seq_size, 0])\n",
    "          \n",
    "      return np.array(x),np.array(y)\n",
    "      \n",
    "\n",
    "  seq_size = 10  # Number of time steps to look back \n",
    "  #Larger sequences (look further back) may improve forecasting.\n",
    "\n",
    "  trainX, trainY = to_sequences(train, seq_size)\n",
    "  testX, testY = to_sequences(test, seq_size)\n",
    "\n",
    "  print(\"Shape of training set: {}\".format(trainX.shape))\n",
    "  print(\"Shape of test set: {}\".format(testX.shape))\n",
    "\n",
    "  trainX = trainX.reshape((trainX.shape[0], 1, 1, 1, seq_size))\n",
    "  testX = testX.reshape((testX.shape[0], 1, 1, 1, seq_size))\n",
    "\n",
    "  model = Sequential()\n",
    "  model.add(ConvLSTM2D(filters=64, kernel_size=(1,1), activation='relu', input_shape=(1, 1, 1, seq_size)))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(32))\n",
    "  model.add(Dense(1))\n",
    "  model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "  monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=20,verbose=1, mode='auto', restore_best_weights=True)\n",
    "  model.summary()\n",
    "  print('Train...')\n",
    "\n",
    "  model.fit(trainX, trainY, validation_data=(testX, testY),\n",
    "            verbose=2, epochs=100)\n",
    "\n",
    "\n",
    "  # make predictions\n",
    "\n",
    "  trainPredict = model.predict(trainX)\n",
    "  testPredict = model.predict(testX)\n",
    "\n",
    "  trainPredict = scaler.inverse_transform(trainPredict)\n",
    "  trainY = scaler.inverse_transform([trainY])\n",
    "  testPredict = scaler.inverse_transform(testPredict)\n",
    "  testY = scaler.inverse_transform([testY])\n",
    "\n",
    "  y_true = scaler.inverse_transform(dataset)[-360:]\n",
    "  y_pred = testPredict\n",
    "  y_pred = np.round(y_pred,0)\n",
    "\n",
    "  if np.max(y_pred) > np.max(y_true):\n",
    "    deviance.append('Positive')\n",
    "  else:\n",
    "    deviance.append('Negative')\n",
    "  place.append(i)\n",
    "\n",
    "\n",
    "  plt.plot(y_true, label='Actual')\n",
    "  plt.plot(y_pred, label='Predicted')\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "result = pd.DataFrame()\n",
    "result['Place'], result['Deviance'] = place, deviance\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time)) #print total time taken to run code \n",
    "\n",
    "result1 = result.loc[result['Deviance'] == 'Positive']\n",
    "\n",
    "result = result.sort_values(by='Place')\n",
    "\n",
    "result2 = result1.rename(columns = {'Place': 'N_Revenue'}, inplace = True)\n",
    "dev = []\n",
    "ar = []\n",
    "for i in adm_name.N_Revenue:\n",
    "  if i in list(result1.N_Revenue):\n",
    "    dev.append(1)\n",
    "    ar.append(i)\n",
    "  else:\n",
    "    dev.append(0)\n",
    "    ar.append(i)\n",
    "    \n",
    "adm_name = adm_name.sort_values(by='N_Revenue')\n",
    "adm_name['deviance']=dev\n",
    "\n",
    "ax = adm_name.plot(column='deviance', legend=True, legend_kwds={'label': \"Taluks having Positive Deviance\",\n",
    "\n",
    "                        'orientation': \"vertical\"}, figsize=(12, 12));\n",
    "\n",
    "ax.set_title('Telangana Data Powered Positive Deviance for Crop Fire')\n",
    "\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(\"output/LSTM_taluk.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f104257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = []\n",
    "ar = []\n",
    "for i in adm_name.N_Revenue:\n",
    "  if i in list(result1.N_Revenue):\n",
    "    dev.append(1)\n",
    "    ar.append(i)\n",
    "  else:\n",
    "    dev.append(0)\n",
    "    ar.append(i)\n",
    "    \n",
    "adm_name = adm_name.sort_values(by='N_Revenue')\n",
    "adm_name['deviance']=dev\n",
    "\n",
    "ax = adm_name.plot(column='deviance', legend=True, legend_kwds={'label': \"Taluks having Positive Deviance\",\n",
    "\n",
    "                        'orientation': \"vertical\"}, figsize=(12, 12));\n",
    "\n",
    "ax.set_title('Telangana Data Powered Positive Deviance for Crop Fire')\n",
    "\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(\"output/LSTM_taluk.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e24d75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
